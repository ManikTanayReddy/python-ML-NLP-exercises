{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db7550c",
   "metadata": {},
   "source": [
    " Q. Day-48 Write a Python program using the Hugging Face 'transformers' library to summarize a short paragraph. Use any open source LLM model from the hub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f085251f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\edbid\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\edbid\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad4812d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec827b2377ab4f5eb602fd5e68bd3c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Failed to import transformers.models.bart.modeling_tf_bart because of the following error (look up to see its traceback):\n",
      "Keras cannot be imported. Check that it is installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edbid\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\edbid\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def summarize_paragraph(paragraph):\n",
    "    \"\"\"\n",
    "    Summarizes a paragraph using a Hugging Face Transformers model.\n",
    "\n",
    "    Args:\n",
    "        paragraph (str): The paragraph to summarize.\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Choose a suitable summarization model. \"facebook/bart-large-cnn\" is a popular choice.\n",
    "        # Another good option is \"google/pegasus-xsum\" for extremely concise summaries.\n",
    "        # \"sshleifer/distilbart-cnn-12-6\" is a smaller, faster alternative.\n",
    "        summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "        summary = summarizer(paragraph, max_length=150, min_length=30, do_sample=False)[0]['summary_text']\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "paragraph = \"\"\"\n",
    "The field of natural language processing (NLP) has seen significant advancements in recent years. \n",
    "Transformer models, such as BERT and GPT, have revolutionized the way machines understand and generate human language. \n",
    "These models, pre-trained on massive amounts of text data, can perform various NLP tasks, including text summarization, \n",
    "sentiment analysis, and machine translation. Hugging Face's Transformers library provides easy access to these models, \n",
    "making it simpler for developers and researchers to experiment with and apply state-of-the-art NLP techniques. \n",
    "The accessibility of these tools has accelerated progress in the field, leading to more sophisticated and practical \n",
    "applications of NLP in areas such as customer service, content creation, and information retrieval.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_paragraph(paragraph)\n",
    "\n",
    "if summary:\n",
    "    print(\"Original Paragraph:\")\n",
    "    print(paragraph)\n",
    "    print(\"\\nSummary:\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b607c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
